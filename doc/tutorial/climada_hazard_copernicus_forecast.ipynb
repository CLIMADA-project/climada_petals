{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76e20689",
   "metadata": {},
   "source": [
    "## Copernicus Seasonal Forecast Module\n",
    "\n",
    "This module is developed to manage seasonal forecast data from the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu) (CDS) for the [U-CLIMADAPT project](https://www.copernicus-user-uptake.eu/user-uptake/details/responding-to-the-impact-of-climate-change-u-climadapt-488). \n",
    "It offers comprehensive tools for downloading, processing, computing climate indices, and generating hazard objects based on seasonal forecast datasets, particularly [Seasonal forecast daily and subdaily data on single levels](https://cds.climate.copernicus.eu/datasets/seasonal-original-single-levels?tab=overview). \n",
    "The module is tailored to integrate seamlessly with the [CLIMADA](https://climada.ethz.ch/)(CLIMate ADAptation) platform, supporting climate risk assessment and the development of effective adaptation strategies.\n",
    "\n",
    "Features:\n",
    "- Download seasonal forecast data from CDS\n",
    "- Process raw data into climate indices\n",
    "- Calculate various heat-related indices (e.g., Maximum Temperature, Tropical Nights)\n",
    "- Create CLIMADA Hazard objects for further risk analysis\n",
    "- Visualize hazard data\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "1. CDS account and API key:\n",
    "   Register at https://cds-beta.climate.copernicus.eu\n",
    "\n",
    "2. CDS API client installation:\n",
    "   pip install cdsapi\n",
    "\n",
    "3. CDS API configuration:\n",
    "   Create a .cdsapirc file in your home directory with your API key and URL.\n",
    "   For instructions, visit: https://cds-beta.climate.copernicus.eu/how-to-api#install-the-cds-api-client\n",
    "\n",
    "4. Dataset Terms and Conditions: After selecting the dataset to download, make \n",
    "   sure to accept the terms and conditions on the corresponding dataset webpage in the CDS portal before running this notebook. Here, https://cds.climate.copernicus.eu/datasets/seasonal-original-single-levels?tab=download.\n",
    "\n",
    "Usage:\n",
    "This module is typically imported and used within larger scripts or applications for climate data processing\n",
    "and risk assessment. See individual function docstrings for specific usage instructions.\n",
    "\n",
    "Note:\n",
    "Ensure you have the necessary permissions and comply with the CDS data usage policies when using this module. You can view the terms and conditions at https://cds.climate.copernicus.eu/datasets/seasonal-original-single-levels?tab=download. You can find them at the bottom of the download page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170187ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import warnings\n",
    "import datetime as dt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from climada.hazard import Hazard\n",
    "from climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard import SeasonalForecast\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50ea48c5-b435-47e0-a178-a1d08742fcad",
   "metadata": {},
   "source": [
    "### Set up module parameters\n",
    "\n",
    "To configure the module for working with Copernicus forecast data and converting it into a hazard object for CLIMADA, you will need to define several essential parameters. These settings are crucial as they specify the type of data to be retrieved, the format, the forecast period, and the geographical area of interest. These parameters influence how the forecast data is processed and transformed into a hazard object.\n",
    "\n",
    "Below, we outline these parameters and use an example for the \"Maximum Temperature\" index to demonstrate the seasonal forecast functionality.\n",
    "\n",
    "To learn more about what these parameters entail and their significance, please refer to the [documentation on the CDS webpage](https://cds-beta.climate.copernicus.eu/datasets/seasonal-original-single-levels?tab=overview).\n",
    "\n",
    "#### Overview of parameters\n",
    "\n",
    "**index_metric**: Defines the type of index to be calculated. The current options available are 'HIA' (Heat Index Adjusted), 'HIS' (Heat Index Simplified), 'Tmean' (Mean Temperature), 'Tmin' (Minimum Temperature), 'Tmax' (Maximum Temperature), 'HW' (Heat Wave), 'TR' (Tropical Nights), 'TX30' (Hot Days), 'HUM' (Humidex), 'RH' (Relative Humidity), 'AT' (Apparent Temperature), and 'WBGT' (Wet Bulb Globe Temperature (Simple)).\n",
    "\n",
    "**Heat Wave Parameters (specific to \"HW\" hazard)**: If index_metric is set to 'HW' for heat wave calculations, additional parameters can be specified to fine-tune the heat wave detection:\n",
    "\n",
    "- threshold: Temperature threshold above which days are considered part of a heat wave. Default is 27°C.\n",
    "- min_duration: Minimum number of consecutive days above the threshold required to define a heat wave event. Default is 3 days.\n",
    "- max_gap: Maximum allowable gap (in days) between two heat wave events to consider them as one single event. Default is 0 days.\n",
    "\n",
    "**Tropical Nights Parameters (specific to \"TR\" hazard)**: If index_metric is set to 'TR' for tropical nights, an additional parameter can be specified to set the threshold:\n",
    "\n",
    "- threshold: Nighttime temperature threshold, above which a night is considered \"tropical.\" Default is 20°C.\n",
    "\n",
    "**format** : Specifies the format of the data to be downloaded, \"grib\" or \"netcdf\". Copernicus do **NOT** recommended netcdf format for operational workflows since conversion to netcdf is considered experimental. [More information here](https://confluence.ecmwf.int/display/CKB/GRIB+to+netCDF+conversion+on+new+CDS+and+ADS+systems).\n",
    "\n",
    "**originating_centre**: Identifies the source of the data. A standard choice is \"dwd\" (German Weather Service), one of eight providers including ECMWF, UK Met Office, Météo France, CMCC, NCEP, JMA, and ECCC.\n",
    "\n",
    "**system**: Refers to a specific model or configuration used for forecasts. In this script, the default value is \"21,\" which corresponds to the GCSF (German Climate Forecast System) [version 2.1](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020MS002101). More details can be found in the [CDS documentation](https://cds-beta.climate.copernicus.eu/datasets/seasonal-original-single-levels?tab=documentation).\n",
    "\n",
    "**year_list**: A list of years for which data should be downloaded and processed.\n",
    "\n",
    "**initiation_month**: A list of the months in which the forecasts are initiated. Example: [\"March\", \"April\"].\n",
    "\n",
    "**lead_time_months**: Specifies the months relative to the forecast's initiation month for which the data is forecasted. Example: [\"June\", \"July\", \"August\"] indicates forecasts for these months. The maximum available is 7 months.\n",
    "\n",
    "**area_selection**: This determines the geographical area for which the data should be downloaded. It can be set to\n",
    "- \"global\" (gobal data is downloaded)\n",
    "- a list of ISO alpha-3 codes for different countries, e.g., [\"DEU\", \"CHE\"] for Germany and Switzerland. See this [wikipedia page](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3) for the country codes. Note that the **joint region** will be downloaded and processed, i.e., handling data for [\"DEU\", \"CHE\"] and then for [\"CHE\"] will download and generate two sets of data.\n",
    "- a list of four numbers corresponding to the geographical bounds (in degrees; EPSG:4326), specified as [north, west, south, east]. \n",
    "\n",
    "**overwrite**: Boolean flag that, when set to True, forces the system to redownload and reprocess existing files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2acc712-baa8-45d0-ad98-85814ad13f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation for HW: Heat Wave: Identifies heat waves as periods with temperatures above a threshold.\n",
      "Required variables: 2m_temperature\n"
     ]
    }
   ],
   "source": [
    "# We define above parameters for an example \n",
    "index_metric = \"HW\" \n",
    "format = \"grib\"  # 'grib' or 'netcdf'\n",
    "originating_centre =  \"dwd\"\n",
    "system =  \"21\" \n",
    "valid_period = [\"May\", \"May\"]\n",
    "year_list = [2022]\n",
    "initiation_month = [\"April\"]\n",
    "area_selection = [\"ITA\"]\n",
    "overwrite = False\n",
    "\n",
    "# Parameters for Heat Waves \n",
    "threshold = 27\n",
    "min_duration = 3\n",
    "max_gap = 0\n",
    "\n",
    "# Parameters for Tropical Nights \n",
    "threshold_tr = 20\n",
    "\n",
    "# Describe the selected climate index and the associated input data\n",
    "handler = SeasonalForecast(\n",
    "    index_metric=index_metric,\n",
    "    year_list=year_list,\n",
    "    valid_period=valid_period,\n",
    "    initiation_month=initiation_month,\n",
    "    area_selection=area_selection,  # Correct parameter name\n",
    "    format=format,\n",
    "    originating_centre=originating_centre,\n",
    "    system=system,\n",
    "    )\n",
    "\n",
    "handler.explain_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee00c8a7-fcb7-4a86-99ed-4aee29c7f08b",
   "metadata": {},
   "source": [
    "### Download and Process Data\n",
    "\n",
    "The `handler.download_and_process_data` method in CLIMADA efficiently retrieves and organizes Copernicus forecast data. It checks for existing files to avoid redundant downloads, stores data by format (grib or netCDF), year, month. Then the files are processed for further analysis, such as calculating climate indices or creating hazard objects within CLIMADA. Here are the aspects of this process:\n",
    "\n",
    "- **Data Download**: The method downloads the forecast data for the selected years, months, and regions. The data is retrieved in **grib** or **netCDF** formats, which are commonly used for storing meteorological data. If the required files already exist in the specified directories, the system will skip downloading them, as indicated by the log messages such as:  \n",
    "  *\"Corresponding grib file SYSTEM_DIR/copernicus_forecast/input_data/dwd/grib/2022/06/t2m_area-16_63_47_4_202206.grib already exists.\"*\n",
    "\n",
    "  seasonal_forecasts/dwd/2021/04/downloaded_data/grib/tmean_area12_47_41_20.grib\n",
    "\n",
    "- **Data Processing**: After downloading (or confirming the existence of) the files, the system converts them into daily **netCDF** files. This format suseful for working with multi-dimensional climate data. The log messages confirm the existence or creation of these files, for example:  \n",
    "  *\"Daily file SYSTEM_DIR/copernicus_forecast/input_data/netcdf/daily/dwd/2022/06/t2m_area-16_63_47_4_202206.nc already exists.\"*\n",
    "\n",
    "- **Geographic and Temporal Focus**: The files are generated for a specific time frame (e.g., June and July 2022) and a predefined geographic region, as specified by the parameters such as `area_selection`, `month_list`, and `year_list`. This ensures that only the selected data for your analysis is downloaded and processed.\n",
    "\n",
    "- **Data Completeness**: Messages like \"already exists\" ensure that you do not redundantly download or process data, saving time and computing resources. However, if the data files are missing, they will be downloaded and processed as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69229b74-d49b-4696-ac56-2530950548fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single overwrite check\n",
      "2024-12-13 09:40:59,790 - climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard - INFO - /Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/downloaded_data/grib/hw_area4_49_33_20.grib already exists.\n",
      "single overwrite check\n",
      "2024-12-13 09:41:08,026 - climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard - INFO - Daily file saved to /Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/processed_data/hw_area4_49_33_20_daily.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'downloaded_data': {(2022,\n",
       "   '04',\n",
       "   '05_05'): PosixPath('/Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/downloaded_data/grib/hw_area4_49_33_20.grib')},\n",
       " 'processed_data': {(2022,\n",
       "   '04',\n",
       "   '05_05'): PosixPath('/Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/processed_data/hw_area4_49_33_20_daily.nc')}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download and process data\n",
    "handler.download_and_process_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7142655-26bd-41a9-8a7a-1f2a36e57fc4",
   "metadata": {},
   "source": [
    "### Calculate Climate Indices\n",
    "\n",
    "When you use the `handler.calculate_index` method in CLIMADA to compute specific climate indices (such as Maximum Temperature), the generated output is saved and organized in a structured format for further analysis. Here some details:\n",
    "\n",
    "- **Index Calculation**: The method processes seasonal forecast data to compute the selected index for the chosen years, months, and regions. This index represents a specific climate condition, such as the number of Maximum Temperature (\"Tmax\") over the forecast period, as defined in the parameters.\n",
    "\n",
    "- **Data Storage**: The calculated index data is saved in **netCDF** format. These files are automatically saved in directories specific to the index and time period. The file paths are printed below the processing steps. For example, the computed index values are stored in:  \n",
    "  *\"SYSTEM_DIR/copernicus_data/seasonal_forecasts/dwd/2021/03/indices/Tmax/daily_area12_47_41_20.nc\"*. \n",
    "\n",
    "  Similarly, the statistics of the index (e.g., mean, max, min, std) are saved in:  \n",
    "  *\"SYSTEM_DIR/copernicus_data/seasonal_forecasts/dwd/2021/03/indices/Tmax/stats_area12_47_41_20.nc\"*. \n",
    "  These files ensure that both the raw indices and their statistical summaries are available for detailed analysis.\n",
    "  \n",
    "  Each file contains data for a specific month and geographic region, as defined in the parameters. This allows you to analyze how the selected climate index varies over time and across different locations.\n",
    "\n",
    "- **Completeness of Data Processing**: Messages 'Index Tmax successfully calculated and saved for...' confirm the successful calculation and storage of the index, ensuring that all requested data has been processed and saved correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d703f84-0749-4003-9fef-6f0ffaccb8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 09:41:08,060 - climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard - INFO - Processing index HW for year 2022, initiation month 04.\n",
      "multiple files overwrite check\n",
      "2024-12-13 09:41:09,473 - climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard - INFO - Saved daily index to /Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/indices/HW/daily_area4_49_33_20.nc\n",
      "2024-12-13 09:41:09,479 - climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard - INFO - Saved monthly index to /Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/indices/HW/monthly_area4_49_33_20.nc\n",
      "2024-12-13 09:41:09,488 - climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard - INFO - Saved stats index to /Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/indices/HW/stats_area4_49_33_20.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(2022,\n",
       "  '04',\n",
       "  '05_05'): {'daily': PosixPath('/Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/indices/HW/daily_area4_49_33_20.nc'), 'monthly': PosixPath('/Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/indices/HW/monthly_area4_49_33_20.nc'), 'stats': PosixPath('/Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/indices/HW/stats_area4_49_33_20.nc')}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate index\n",
    "handler.calculate_index(hw_threshold=threshold, hw_min_duration=min_duration, hw_max_gap=max_gap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3166a41f-874d-4e22-aad4-7be71d08e456",
   "metadata": {},
   "source": [
    "### Calculate a Hazard Object\n",
    "\n",
    "When you use the `handler.process_and_save_hazards` method in CLIMADA to convert processed index from Copernicus forecast data into a hazard object:\n",
    "\n",
    "- **Hazard Object Creation**: The method processes seasonal forecast data for specified years and months, converting these into hazard objects. These objects encapsulate potential risks associated with specific weather events or conditions, such as Maximum Temperature ('Tmax') indicated in the parameters, over the forecast period.\n",
    "\n",
    "- **Data Storage**: The hazard data for each ensemble member of the forecast is saved as HDF5 files. These files are automatically stored in specific directories corresponding to each month and type of hazard. The file paths are printed below the processing steps. For example, *\"/SYSTEM_DIR/copernicus_data/seasonal_forecasts/dwd/2021/03/hazard/Tmax/area12_47_41_20.hdf5\"*.\n",
    " HDF5 is a versatile data model that efficiently stores large volumes of complex data.\n",
    " \n",
    " Each file is specific to a particular month and hazard scenario ('Tmax' in this case) and covers all ensemble members for that forecast period, aiding in detailed risk analysis.\n",
    "\n",
    "- **Completeness of Data Processing**: Messages like 'Completed processing for 2022-07. Data saved in...' confirm the successful processing and storage of the hazard data for that period, ensuring that all requested data has been properly handled and stored.\n",
    "\n",
    "#### Visualizing the Calculated Hazard Object\n",
    "\n",
    "Once the hazard object has been successfully calculated, the last element created is printed for visualization. This is important for several reasons:\n",
    "\n",
    "- **Initial Data Inspection**: The visualization allows you to view a slice of the forecast data, providing a quick check of the results. This initial glimpse helps you verify that the data processing was successful and provides insights into the distribution of the hazard (in this case, Maximum Temperature) across the area of interest.\n",
    "\n",
    "- **Geographic Accuracy**: The map helps you verify if the correct geographic region was processed and plotted. This is particularly useful as it allows immediate feedback on whether the user-defined boundaries or selected areas (e.g., Germany and Switzerland) were captured correctly.\n",
    "\n",
    "- **Data Quality Check**: Visualizing the output also serves as a preliminary quality check, allowing you to detect any unexpected results or anomalies in the data. For instance, the color bar indicating the \"Intensity (days)\" gives an indication of how the hazard index is distributed across the mapped area.\n",
    "\n",
    "- **Quick Workflow Testing**: This step is essential for testing the entire workflow, ensuring that the process is working as expected from data download, processing, and hazard object creation to visualization.\n",
    "\n",
    "This output provides a structured dataset ready for further analysis within the CLIMADA framework, allowing for the evaluation of potential impacts and the planning of mitigation strategies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0d6332-99f8-49f1-b925-26758005c152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 09:41:09,516 - climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard - INFO - Creating hazard for index HW for year 2022, initiation month 04.\n",
      "single overwrite check\n",
      "2024-12-13 09:41:10,160 - climada.hazard.io - INFO - Writing /Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/hazard/HW/area4_49_33_20.hdf5\n",
      "2024-12-13 09:41:10,169 - climada.hazard.centroids.centr - INFO - Writing /Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/hazard/HW/area4_49_33_20.hdf5\n",
      "2024-12-13 09:41:10,215 - climada_petals.hazard.copernicus_interface.create_seasonal_forecast_hazard - INFO - Hazard file saved to /Users/vgebhart/climada/data/copernicus_data/seasonal_forecasts/dwd/2022/init04/valid05_05/hazard/HW/area4_49_33_20.hdf5\n"
     ]
    }
   ],
   "source": [
    "output = handler.save_index_to_hazard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9280e7d",
   "metadata": {},
   "source": [
    "## Example for reading and plotting hazard\n",
    "\n",
    "The saved hazard file can then be read and processed by standard CLIMADA methods. For instance, below, we load the hazard for the last month and plot the intensity per grid point maximized over all forecast ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d99eeca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lead_time_months' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Convert initiation_month to integers\u001b[39;00m\n\u001b[1;32m     11\u001b[0m initiation_month_int \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     month_name_to_number_map[month] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(month, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(month)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m initiation_month\n\u001b[1;32m     14\u001b[0m ]\n\u001b[1;32m     15\u001b[0m lead_time_months_int \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     month_name_to_number_map[month] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(month, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(month)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlead_time_months\u001b[49m\n\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Use the last initiation month as the folder for hazard data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m initiation_month_folder \u001b[38;5;241m=\u001b[39m initiation_month[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lead_time_months' is not defined"
     ]
    }
   ],
   "source": [
    "# Choose the example hazard\n",
    "year = year_list[-1]  # Retrieve the last year in the list for the example\n",
    "\n",
    "# Map month names to their respective numbers\n",
    "month_name_to_number_map = {\n",
    "    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \"May\": 5, \"June\": 6,\n",
    "    \"July\": 7, \"August\": 8, \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "}\n",
    "\n",
    "# Convert initiation_month to integers\n",
    "initiation_month_int = [\n",
    "    month_name_to_number_map[month] if isinstance(month, str) else int(month)\n",
    "    for month in initiation_month\n",
    "]\n",
    "lead_time_months_int = [\n",
    "    month_name_to_number_map[month] if isinstance(month, str) else int(month)\n",
    "    for month in lead_time_months\n",
    "]\n",
    "\n",
    "# Use the last initiation month as the folder for hazard data\n",
    "initiation_month_folder = initiation_month[-1]\n",
    "initiation_month_folder_int = month_name_to_number_map[initiation_month_folder]\n",
    "\n",
    "# Retrieve the last lead time month\n",
    "forecast_month = lead_time_months[-1]  # Example is for August\n",
    "forecast_month_int = month_name_to_number_map[forecast_month]\n",
    "\n",
    "# Handle year rollover if forecast month precedes initiation month\n",
    "if forecast_month_int < initiation_month_folder_int:\n",
    "    year += 1\n",
    "\n",
    "# Convert forecast date to ordinal\n",
    "ordinal_date = dt.datetime.fromisoformat(f\"{year}-{forecast_month_int:02d}-01\").toordinal()\n",
    "\n",
    "# Get bounds for the area selection\n",
    "bounds = handler._get_bounds_for_area_selection(area_selection)\n",
    "area_str = f\"area{int(bounds[1])}_{int(bounds[0])}_{int(bounds[2])}_{int(bounds[3])}\"\n",
    "\n",
    "# Define the hazard directory and path based on the initiation month\n",
    "hazard_directory = f\"{handler.data_out}/{originating_centre}/{year}/{initiation_month_folder_int:02d}/hazard/{index_metric}\"\n",
    "hazard_path = f\"{hazard_directory}/{area_str}.hdf5\"\n",
    "\n",
    "# Load the hazard and plot intensity for the selected grid, maximized over ensemble\n",
    "haz = Hazard.from_hdf5(hazard_path)  \n",
    "haz.select(date=[ordinal_date, ordinal_date]).plot_intensity(event=0, smooth=False)  # Plot intensity for the selected event\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e42930f5",
   "metadata": {},
   "source": [
    "## Provide skills in index metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93da52f4",
   "metadata": {},
   "source": [
    "Use `handler.forecast_skills()` to analyze the forecast skill metrics for the selected index. Currently, DWD is the only available provider, and Tmax is the only metric offered, with data covering all months of the year, starting from June.\n",
    "\n",
    "The available skill metrics include:\n",
    "\n",
    "- tasmax_fc_mse (Forecast Model Error): This metric quantifies the forecast error of the model based on the Mean Squared Error (MSE). It serves as an indicator of how much the forecast deviates from observed values.\n",
    "- tasmax_ref_mse (Reference Model Error): This metric provides the error of a reference to a climatological baseline forecast model, offering a benchmark for comparison.\n",
    "- tasmax_msess (Mean Squared Error Skill Score - MSESS): This is a normalised score that evaluates the relative performance of the forecast compared to the reference. Higher values indicate better performance, with values greater than 0 suggesting skill beyond the reference.\n",
    "- tasmax_msessSig (Statistical Significance of MSESS): This metric assesses the statistical significance of the MSESS values. It helps determine whether the skill score is meaningful or a result of random chance, ensuring reliable interpretation.\n",
    "\n",
    "For more detailed information about the dataset, variables, and methodology, please visit the [Zenodo Repository](https://zenodo.org/uploads/14103378?token=eyJhbGciOiJIUzUxMiIsImlhdCI6MTczMTQyODg4OSwiZXhwIjoxNzM1NjAzMTk5fQ.eyJpZCI6IjIyZjVmMDM2LTlkNzAtNDU3YS04Y2MwLTlmZTJiZWJhZjEyZiIsImRhdGEiOnt9LCJyYW5kb20iOiI1NDU1YmEzMjI2NGM1MjIxYjE4M2U0ZGVlOWY4ZTk1ZCJ9.EIt95RzLBSmDfeeek7GFNG9kbYx5mjtsPPaaFWgC9OUU14bTEmgePV00cJfHkIm0mBhjp_4X903JVcPUSVKA5w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast skills are only available for the 'Tmax' index. Current index: HW\n"
     ]
    }
   ],
   "source": [
    "# Call the forecast_skills function\n",
    "handler.forecast_skills()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c39d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3136169053.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from datetime import date.date\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import datetime import date.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99918c35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "day is out of range for month",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[0;32m----> 3\u001b[0m (date(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2022\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mdays\n",
      "\u001b[0;31mValueError\u001b[0m: day is out of range for month"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "(date(2022, 3, 1) - date(2022, 1, 1)).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4289401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climada_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
